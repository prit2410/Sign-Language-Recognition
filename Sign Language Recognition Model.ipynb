{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"sign-language-mnist/sign_mnist_train/sign_mnist_train.csv\"\n",
    "test_dataset_path =  \"sign-language-mnist/sign_mnist_test/sign_mnist_test.csv\"\n",
    "train_dataset = pd.read_csv(train_dataset_path)\n",
    "test_dataset = pd.read_csv(test_dataset_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_set_x_orig = np.array(train_dataset.iloc[:,1:]) # train set features\n",
    "    train_set_y_orig = np.array(train_dataset.iloc[:,:1]) # train set labels\n",
    "    test_set_x_orig = np.array(test_dataset.iloc[:,1:]) # test set features\n",
    "    test_set_y_orig = np.array(test_dataset.iloc[:,:1]) # test set labels\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert to one hot encoding\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the data\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig = load_dataset()\n",
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "X_train = X_train_flatten/255.\n",
    "X_test = X_test_flatten/255.\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 25)\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 27455\n",
      "Number of test examples = 7172\n",
      "X_train shape: (784, 27455)\n",
      "Y_train shape: (25, 27455)\n",
      "X_test shape: (784, 7172)\n",
      "Y_test shape: (25, 7172)\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of training examples = \" + str(X_train.shape[1]))\n",
    "print (\"Number of test examples = \" + str(X_test.shape[1]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tensors\n",
    "def create_placeholders(n_x,n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- size of an image vector (num_px * num_px = 28 * 28 * 1 = 784), 1 because it is a grayscale image\n",
    "    n_y -- number of classes (from 0 to 24)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"tf.float32\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"tf.float32\"\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(shape=[n_x,None],dtype=tf.float32,name=\"X\")\n",
    "    Y = tf.placeholder(shape=[n_y,None],dtype=tf.float32,name=\"Y\")\n",
    "    \n",
    "    return X, Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of parameters ie. Weights, Biases\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes the parameters for the deep neural network with 4 hidden layers\n",
    "    \n",
    "    Returns:\n",
    "    Parameters : A dictionary with the weights and the biases\n",
    "    \"\"\"\n",
    "    W1 = tf.get_variable(\"W1\",[35,784], initializer=tf.contrib.layers.xavier_initialization())\n",
    "    b1 = tf.get_variable(\"b1\",[35,1], initializer=tf.contrib.layers.xavier_initialization())\n",
    "    W2 = tf.get_variable(\"W2\",[30,35], initializer=tf.contrib.layers.xavier_initialization())\n",
    "    b2 = tf.get_variable(\"b2\",[30,1], initializer=tf.contrib.layers.xavier_initialization())\n",
    "    W3 = tf.get_variable(\"W3\",[25,30], initializer=tf.contrib.layers.xavier_initialization())\n",
    "    b3 = tf.get_variable(\"b3\",[25,1], initializer=tf.contrib.layers.xavier_initialization())\n",
    "    parameters = {\"W1\":W1,\n",
    "                  \"b1\":b1,\n",
    "                  \"W2\":W2,\n",
    "                  \"b2\":b2,\n",
    "                  \"W3\":W3,\n",
    "                  \"b3\":b3\n",
    "                 }\n",
    "    \n",
    "    return parameters\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Propagation\n",
    "def forward_prop(X, parameters):\n",
    "    \"\"\"\n",
    "    Function for forward propagation of the computation graph of the deep neural network\n",
    "    Args : \n",
    "    X : Input dataset , images (grayscale)\n",
    "    parameters : Dictionary that contains the weights and the biases\n",
    "    \n",
    "    Returns : \n",
    "    Z3 : Output of the final linear unit\n",
    "    \"\"\"\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    # Calculate the Linear function and activation values for each layer\n",
    "    Z1 = tf.matmul(W1,X)+b1\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.matmul(W2,A1)+b2\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    Z3 = tf.matmul(W3,A2)+b3\n",
    "    \n",
    "    return Z3\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cost function that will be used will be the mean of the summation of Softmax cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the cost \n",
    "def compute_cost(logits,labels):\n",
    "    \"\"\"\n",
    "        Arguments:\n",
    "        logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)\n",
    "        labels -- vector of labels y (1 or 0) \n",
    "        \n",
    "        Returns : \n",
    "        cost : Tensor of the cost function\n",
    "    \"\"\"\n",
    "  \n",
    "    logits = tf.transpose(logits)\n",
    "    labels = tf.transpose(labels)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "    \n",
    "    return cost\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train,Y_train,X_test,Y_test,learning_rate = 0.001,num_epochs=1500):\n",
    "    \"\"\"\n",
    "    Deep NN model for the architecture : LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set\n",
    "    Y_train -- training set\n",
    "    X_test -- test set\n",
    "    Y_test -- test set\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model.\n",
    "    \"\"\"\n",
    "                       \n",
    "    (n_x, m) = X_train.shape                          \n",
    "    n_y = Y_train.shape[0]                            \n",
    "    costs = []          \n",
    "    X,Y = create_placeholders(n_x,n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    # Forward propagation\n",
    "    Z3 = forward_prop(X,parameters)\n",
    "    cost = compute_cost(Z3,Y)\n",
    "    # Optimizer of the model eg. Gradient Descent, Adam, RMSPROP\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    # Initialize the values\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(num_epochs):\n",
    "            _ , epoch_cost = sess.run([optimizer,cost],feed_dict={X:X_train,Y:Y_train})\n",
    "            costs.append(epoch_cost)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    return parameters\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     
     ]
    }
   ],
   "source": [
    "parameters = model(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
